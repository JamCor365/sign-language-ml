{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0e110d",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo para letras dinámicas del LSM\n",
    "\n",
    "En este notebook entrenamos modelos clásicos sobre secuencias dinámicas (videos) correspondientes a letras como J, K, Ñ, Q, X, Z del Lenguaje de Señas Mexicano. Cada secuencia se representa como un vector promedio de sus frames. Se evalúan distintos clasificadores y se guarda el mejor.\n",
    "\n",
    "## 1. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a4db26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frames</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['data/letters/dynamics/J/S1-J-perfil-1/frame_...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['data/letters/dynamics/J/S1-J-perfil-2/frame_...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['data/letters/dynamics/J/S1-J-perfil-3/frame_...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['data/letters/dynamics/J/S1-J-perfil-4/frame_...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['data/letters/dynamics/J/S1-J-perfil-5/frame_...</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              frames label\n",
       "0  ['data/letters/dynamics/J/S1-J-perfil-1/frame_...     J\n",
       "1  ['data/letters/dynamics/J/S1-J-perfil-2/frame_...     J\n",
       "2  ['data/letters/dynamics/J/S1-J-perfil-3/frame_...     J\n",
       "3  ['data/letters/dynamics/J/S1-J-perfil-4/frame_...     J\n",
       "4  ['data/letters/dynamics/J/S1-J-perfil-5/frame_...     J"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "\n",
    "df = pd.read_csv(here() / \"data\" / \"letters\" / \"dynamics_sequences.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d673103",
   "metadata": {},
   "source": [
    "## 2. Vectorización de secuencias (mean pooling)\n",
    "\n",
    "Cada secuencia (carpeta de frames) es convertida en un solo vector promedio, aplicando redimensionamiento y aplanamiento por frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07135eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (620, 12288)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def vectorizar_secuencia(frame_paths):\n",
    "    frames = [cv2.imread(str(here() / f)) for f in frame_paths]\n",
    "    frames = [f for f in frames if f is not None]\n",
    "    arr = np.array([cv2.resize(f, (64,64)).flatten() for f in frames])\n",
    "    return arr.mean(axis=0) if len(arr) > 0 else np.zeros(64*64*3)\n",
    "\n",
    "X = np.vstack(df['frames'].apply(eval).apply(vectorizar_secuencia).to_list())\n",
    "y = df['label'].to_numpy()\n",
    "print(f\"Shape de X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ba9bd",
   "metadata": {},
   "source": [
    "## 3. Reducción de dimensionalidad con PCA\n",
    "\n",
    "Se aplica PCA después de estandarizar los vectores para reducir la dimensionalidad y mejorar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05e11ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original: (620, 12288)\n",
      "Shape tras PCA: (620, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(\"Shape original:\", X.shape)\n",
    "print(\"Shape tras PCA:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc4c797",
   "metadata": {},
   "source": [
    "## 4. División de datos y comparación de clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46eebdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Accuracy promedio (CV): 0.3931\n",
      "Random Forest: Accuracy promedio (CV): 0.8386\n",
      "KNN: Accuracy promedio (CV): 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy promedio (CV): 0.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "modelos = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    scores = cross_val_score(modelo, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(f\"{nombre}: Accuracy promedio (CV): {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fae5a",
   "metadata": {},
   "source": [
    "## 5. Evaluación final y guardado del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249404dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           J       0.85      0.85      0.85        20\n",
      "           K       0.79      0.95      0.86        20\n",
      "           Q       0.68      0.62      0.65        21\n",
      "           X       0.80      0.76      0.78        21\n",
      "           Z       0.95      0.90      0.93        21\n",
      "           Ñ       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.85       124\n",
      "   macro avg       0.85      0.85      0.85       124\n",
      "weighted avg       0.85      0.85      0.84       124\n",
      "\n",
      "✅ Modelo y transformadores guardados.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Entrenar el mejor modelo\n",
    "mejor_modelo = RandomForestClassifier()\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "# Evaluación\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardado\n",
    "joblib.dump(mejor_modelo, here() / \"models\" / \"dynamics_rf.pkl\")\n",
    "joblib.dump(pca, here() / \"models\" / \"pca_gestos.pkl\")\n",
    "joblib.dump(scaler, here() / \"models\" / \"scaler_gestos.pkl\")\n",
    "print(\"✅ Modelo y transformadores guardados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ec7d5",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- Se entrenaron y compararon cuatro clasificadores tradicionales (SVM, Random Forest, KNN y Regresión Logística) usando validación cruzada.\n",
    "- El modelo con mejor rendimiento fue **Random Forest**, alcanzando una precisión promedio (CV) de **0.8386**.\n",
    "- La reducción de dimensionalidad mediante PCA fue efectiva, comprimiendo los vectores de 12,288 dimensiones a solo **5 componentes principales**, manteniendo el 95% de la varianza.\n",
    "- El rendimiento final del modelo Random Forest alcanzó una **accuracy del 85%** en el conjunto de prueba.\n",
    "- Se observó un buen desempeño general en todas las clases dinámicas, destacando el gesto **Ñ** con una precisión y recall perfectos.\n",
    "- Se detectaron algunas dificultades en las letras **Q** y **X**, lo cual podría deberse a variabilidad visual o menor diferenciación entre secuencias.\n",
    "- El modelo final, junto con el PCA y el scaler, fue guardado correctamente para uso posterior.\n",
    "\n",
    "> Estos resultados muestran que, aunque los clasificadores tradicionales pueden lograr buenos resultados, existe potencial para mejorar el rendimiento con modelos secuenciales como LSTM o CNN 3D que aprovechen mejor la naturaleza temporal de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
