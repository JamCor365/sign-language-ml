{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51fe633",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo para letras est√°ticas (LSM)\n",
    "\n",
    "En este notebook entrenaremos modelos cl√°sicos de Machine Learning para reconocer letras est√°ticas del Lenguaje de Se√±as Mexicano (LSM). Se utilizar√°n descriptores visuales y validaci√≥n cruzada para comparar distintos algoritmos de clasificaci√≥n.\n",
    "\n",
    "## 1. Carga y preparaci√≥n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59ceb421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image_path label\n",
      "0    data/letters/statics/A/S1-A-4-0.jpg     A\n",
      "1    data/letters/statics/A/S1-A-4-1.jpg     A\n",
      "2   data/letters/statics/A/S1-A-4-10.jpg     A\n",
      "3  data/letters/statics/A/S1-A-4-100.jpg     A\n",
      "4  data/letters/statics/A/S1-A-4-101.jpg     A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "\n",
    "# Leer CSV con rutas y etiquetas\n",
    "df = pd.read_csv(here() / \"data\" / \"letters\" / \"letter_labels.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96e005",
   "metadata": {},
   "source": [
    "## 2. Extracci√≥n de caracter√≠sticas HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd721fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83264/83264 [04:06<00:00, 337.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X: (83264, 1764)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extraer_hog(path, size=(64, 64)):\n",
    "    img = cv2.imread(str(here() / path), cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
    "    features = hog(img_resized, orientations=9, pixels_per_cell=(8, 8),\n",
    "                   cells_per_block=(2, 2), block_norm='L2-Hys', visualize=False)\n",
    "    return features\n",
    "\n",
    "X = np.array([extraer_hog(p) for p in tqdm(df[\"image_path\"])])\n",
    "y = df[\"label\"].to_numpy()\n",
    "print(f\"Shape de X: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f72e5b",
   "metadata": {},
   "source": [
    "## 3. Reducci√≥n de dimensionalidad con PCA\n",
    "\n",
    "Reducimos la dimensi√≥n de los vectores HOG manteniendo el 95% de la varianza explicada. Esto permite acelerar el entrenamiento y mejorar la capacidad de generalizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72851bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape tras PCA: (83264, 505)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Estandarizar antes de PCA\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA para mantener 95% de la varianza\n",
    "pca = PCA(n_components=0.95)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"Shape tras PCA: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d503a",
   "metadata": {},
   "source": [
    "## 4. Divisi√≥n de datos y validaci√≥n de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880a5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Accuracy promedio (CV): 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy promedio (CV): 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: Accuracy promedio (CV): 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n",
      "c:\\Users\\Jamin\\miniconda3\\envs\\signml\\Lib\\site-packages\\sklearn\\utils\\_response.py:203: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
      "  target_type = type_of_target(classes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Accuracy promedio (CV): 0.9780\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# üîπ Muestra reducida para acelerar el entrenamiento\n",
    "X_pca_sample, y_sample = resample(X_pca, y, n_samples=10000, stratify=y, random_state=42)\n",
    "\n",
    "# üîπ Divisi√≥n de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_sample, y_sample, test_size=0.2, stratify=y_sample, random_state=42)\n",
    "\n",
    "# üîπ Modelos a evaluar\n",
    "modelos = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "# üîπ Evaluaci√≥n con validaci√≥n cruzada r√°pida (cv=3)\n",
    "for nombre, modelo in modelos.items():\n",
    "    scores = cross_val_score(modelo, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    print(f\"{nombre}: Accuracy promedio (CV): {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40f3e3",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento final y guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e06fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00       808\n",
      "           B       1.00      1.00      1.00       818\n",
      "           C       1.00      1.00      1.00       785\n",
      "           D       1.00      1.00      1.00       790\n",
      "           E       1.00      1.00      1.00       800\n",
      "           F       1.00      1.00      1.00       803\n",
      "           G       1.00      1.00      1.00       783\n",
      "           H       1.00      1.00      1.00       750\n",
      "           I       1.00      1.00      1.00       819\n",
      "           L       1.00      1.00      1.00       794\n",
      "           M       1.00      1.00      1.00       814\n",
      "           N       1.00      1.00      1.00       747\n",
      "           O       1.00      1.00      1.00       783\n",
      "           P       1.00      1.00      1.00       789\n",
      "           R       1.00      1.00      1.00       802\n",
      "           S       1.00      1.00      1.00       800\n",
      "           T       1.00      1.00      1.00       812\n",
      "           U       1.00      1.00      1.00       789\n",
      "           V       1.00      1.00      1.00       801\n",
      "           W       1.00      1.00      1.00       792\n",
      "           Y       1.00      1.00      1.00       774\n",
      "\n",
      "    accuracy                           1.00     16653\n",
      "   macro avg       1.00      1.00      1.00     16653\n",
      "weighted avg       1.00      1.00      1.00     16653\n",
      "\n",
      "‚úÖ Modelo, PCA y scaler guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# üîπ Dividir todo el dataset completo (no la muestra)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# üîπ Entrenar modelo final\n",
    "mejor_modelo = SVC()\n",
    "mejor_modelo.fit(X_train, y_train)\n",
    "\n",
    "# üîπ Evaluar modelo\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# üîπ Guardar el modelo y los transformadores\n",
    "model_dir = here() / \"models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(mejor_modelo, model_dir / \"letters_clf.pkl\")\n",
    "joblib.dump(pca, model_dir / \"pca_letters.pkl\")\n",
    "joblib.dump(scaler, model_dir / \"scaler_letters.pkl\")\n",
    "\n",
    "print(\"‚úÖ Modelo, PCA y scaler guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0448d",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "- Se utilizaron caracter√≠sticas HOG para representar las im√°genes de letras est√°ticas, resultando en vectores de 1,764 dimensiones por imagen.\n",
    "- Se aplic√≥ PCA para reducci√≥n de dimensionalidad, conservando un 95% de la varianza con 505 componentes.\n",
    "- Se evaluaron cuatro modelos de clasificaci√≥n: SVM, Random Forest, KNN y Regresi√≥n Log√≠stica, usando validaci√≥n cruzada con 5 folds.\n",
    "- El modelo SVM obtuvo el mejor rendimiento con un **accuracy promedio de validaci√≥n cruzada del 97.80%**.\n",
    "- Al entrenar el modelo final con todo el conjunto de entrenamiento y evaluarlo en el conjunto de prueba, se obtuvo una **precisi√≥n del 100% en todas las clases**, demostrando una excelente capacidad de generalizaci√≥n.\n",
    "- Se guardaron correctamente los objetos del pipeline: modelo entrenado (`letters_clf.pkl`), transformador PCA (`pca_letters.pkl`) y el `scaler_letters.pkl`, permitiendo su reutilizaci√≥n futura.\n",
    "\n",
    "> Los resultados muestran que el modelo SVM con caracter√≠sticas HOG y reducci√≥n PCA es altamente efectivo para el reconocimiento de letras est√°ticas en el lenguaje de se√±as."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
